This model is a multi-output regression neural network (MLP) designed to predict four continuous target parameters (σ0, σa, A, and E) from 18 input features. In terms of data preparation, the last four samples are held out as an independent test set, while the remaining data are used for training and validation. Both inputs and outputs are scaled to the 0–1 range using Min–Max normalization to reduce the impact of different feature magnitudes on training. The network consists of three hidden layers with 128 neurons each, using ReLU activation functions, and includes L2 regularization to help prevent overfitting. The output layer contains four linear neurons to support simultaneous prediction of all targets, and its bias terms are initialized with the mean of the training targets to improve training stability. The model is trained using the Adam optimizer with mean squared error (MSE) as the loss function over 500 epochs. For evaluation, a 10-fold cross-validation strategy is applied, where scalers are fitted within each fold to avoid data leakage, and R² scores are computed for each output and summarized with mean and standard deviation to assess overall performance and consistency. After cross-validation, a final model is trained on the full training set and used to generate predictions for the test samples. To improve interpretability, SHAP is used to quantify feature contributions on the validation set, and the results are visualized using bee swarm plots and mean absolute SHAP bar charts to highlight the most influential inputs for each target.
